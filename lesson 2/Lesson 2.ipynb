{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocational-brooklyn",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T10:24:58.975209Z",
     "start_time": "2023-10-03T10:24:58.524513Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "general-marine",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T10:24:59.090536Z",
     "start_time": "2023-10-03T10:24:58.786615Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('labeledTrainData.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "radical-danger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T10:24:59.090962Z",
     "start_time": "2023-10-03T10:24:59.042411Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = df.review.tolist()\n",
    "sentiment = df.sentiment.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    preprocessed_text = ' '.join(stemmed_tokens)\n",
    "    return preprocessed_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-03T10:24:59.091017Z",
     "start_time": "2023-10-03T10:24:59.044686Z"
    }
   },
   "id": "142e3be3e279603c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "behind-channels",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T10:24:59.091090Z",
     "start_time": "2023-10-03T10:24:59.049269Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def space_tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "    \n",
    "    \n",
    "def get_vocab(texts):\n",
    "    preprocessed_texts = [preprocess_text(text) for text in texts]\n",
    "    tokens = [token for text in preprocessed_texts for token in space_tokenize(text)]\n",
    "    word_counts = Counter(tokens)\n",
    "    sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    vocab = [word for word, _ in sorted_words]\n",
    "    return vocab\n",
    "\n",
    "class BOWencoder:\n",
    "    def __init__(self, vocab=None, tokenize=space_tokenize):\n",
    "        self.vocab = vocab\n",
    "        self.vocab2idx = self.get_vocab2idx(vocab)\n",
    "        self.tokenize = tokenize\n",
    "        \n",
    "    def encode_single_text(self, text):\n",
    "        tokens = self.tokenize(text)\n",
    "        bow_vector = [0] * len(self.vocab)\n",
    "        for token in tokens:\n",
    "            if token in self.vocab2idx:\n",
    "                idx = self.vocab2idx[token]\n",
    "                bow_vector[idx] += 1          \n",
    "        return bow_vector\n",
    "        \n",
    "    def encode_texts(self, texts):\n",
    "        encoded_texts = [self.encode_single_text(text) for text in texts]\n",
    "        return encoded_texts\n",
    "        \n",
    "    def get_vocab2idx(self, vocab):\n",
    "        vocab2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "        return vocab2idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "guided-playback",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T10:24:59.091124Z",
     "start_time": "2023-10-03T10:24:59.054713Z"
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, n_classes):\n",
    "        self.n_classes = n_classes\n",
    "        self.class_probs = {}\n",
    "        self.conditional_probabilities = {}\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for class_label in range(self.n_classes):\n",
    "            class_indices = [i for i, label in enumerate(y) if label == class_label]\n",
    "            class_instances = [X[i] for i in class_indices]\n",
    "            self.class_probs[class_label] = len(class_instances) / len(y)\n",
    "    \n",
    "            conditional_probs = {}  # Словарь для хранения условных вероятностей\n",
    "            for feature_idx in range(len(self.vocab)):\n",
    "                feature_prob = (sum(instance[feature_idx] for instance in class_instances) + 1) / (len(class_instances) + 2)  # Пример сглаживания Лапласа\n",
    "                conditional_probs[feature_idx] = feature_prob\n",
    "            self.conditional_probabilities[class_label] = conditional_probs\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for instance in X:\n",
    "            max_prob = -1\n",
    "            predicted_class = None\n",
    "            for class_label in range(self.n_classes):\n",
    "                class_prob = self.class_probs[class_label]\n",
    "                conditional_probs = self.conditional_probabilities[class_label]\n",
    "                instance_prob = 1.0  # Инициализируйте вероятность экземпляра\n",
    "                for feature_idx, feature_value in enumerate(instance):\n",
    "                    conditional_prob = conditional_probs.get(feature_idx, 1.0) if feature_value else 1.0\n",
    "                    instance_prob *= conditional_prob\n",
    "                class_prob *= instance_prob\n",
    "                if class_prob > max_prob:\n",
    "                    max_prob = class_prob\n",
    "                    predicted_class = class_label\n",
    "            predictions.append(predicted_class)\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mobile-entrepreneur",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T10:26:43.893620Z",
     "start_time": "2023-10-03T10:24:59.057446Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, sentiment)\n",
    "vocab = get_vocab(X_train)\n",
    "bow_encoder = BOWencoder(vocab=vocab)\n",
    "X_train = bow_encoder.encode_texts(X_train)\n",
    "X_test = bow_encoder.encode_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "organic-workstation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T10:29:10.134853Z",
     "start_time": "2023-10-03T10:26:43.931624Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NaiveBayesClassifier(n_classes=2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вывод полных ревью\n",
    "def classify_and_print_description(text):\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "\n",
    "    text_vector = bow_encoder.encode_single_text(preprocessed_text)\n",
    "\n",
    "    prediction = model.predict([text_vector])\n",
    "\n",
    "    if prediction[0] == 1:\n",
    "        print(\"Положительное окружение слова 'view':\")\n",
    "    \n",
    "        positive_description = df[df['sentiment'] == 1]['review'].values[0]\n",
    "        print(positive_description)\n",
    "    else:\n",
    "        print(\"Отрицательное окружение слова 'view':\")\n",
    "        \n",
    "        negative_description = df[df['sentiment'] == 0]['review'].values[0]\n",
    "        print(negative_description)\n",
    "\n",
    "for text in texts:\n",
    "    classify_and_print_description(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#вывод предложений\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def classify_and_print_description(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if \"view\" in sentence.lower():\n",
    "    \n",
    "            preprocessed_sentence = preprocess_text(sentence)\n",
    "\n",
    "            sentence_vector = bow_encoder.encode_single_text(preprocessed_sentence)\n",
    "\n",
    "            prediction = model.predict([sentence_vector])\n",
    "\n",
    "            if prediction[0] == 1:\n",
    "                print(f\"Положительное окружение слова 'view': {sentence}\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"Отрицательное окружение слова 'view': {sentence}\")\n",
    "            \n",
    "\n",
    "for text in texts:\n",
    "    classify_and_print_description(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
